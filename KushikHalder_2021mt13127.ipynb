{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hqgxlSM9CeL"
      },
      "source": [
        "# Linear Models For Classification\n",
        "\n",
        "In this notebook we look at how to implement linear models in python.\n",
        "\n",
        "The following datasets will be used for analysis -\n",
        "\n",
        "1. [Bikeshare](https://drive.google.com/file/d/1mzUgrPg3Dndy-DFy8rf6Dqh6-jX1FaSe/view?usp=sharing)\n",
        "2. [Stock-Market](https://drive.google.com/file/d/1bFNQ0DzvFAbNKa5G8PA-aLRo35xSYSBC/view?usp=sharing)\n",
        "\n",
        "\n",
        "From before we use the \n",
        "\n",
        "1. `numpy` library for dealing with numerical datasets\n",
        "2. `pandas` is used to manipilate the datasets using the DataFrame object.\n",
        "3. `matplotlib` is used to plot the figures.\n",
        "4. Use `sklearn` to implement logistic regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I-8xQ4d21lAq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/\"\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"Notebooks/Data/Smarket.csv\"\n",
        "\n",
        "def fetch_data(housing_url=HOUSING_URL):\n",
        "    urllib.request.urlretrieve(housing_url, \"/content/Smarket.csv\")\n",
        "\n",
        "fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cT0j34pJ8Lkd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC8j3Omj9b2t"
      },
      "source": [
        "First lets look at the stock market data. The aim is to predict the `Direction` variable using `lag_*` and `Volume` variables.\n",
        "\n",
        "Before any analysis can be done we need to prepare the data by -\n",
        "\n",
        "1. Encoding the output/response Up/Down as 0/1.\n",
        "2. We then remove the `Year`, `Today` and `Direction` to get our independent variables.\n",
        "3. Note that the sign of `Today` essentially dictates the Up/Down direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgeyusYf9jir",
        "outputId": "4aa0208a-df7b-4f86-8740-92a33692cb00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
            "1  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
            "2  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
            "3  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
            "4  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
            "5  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/Smarket.csv\", index_col=0)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t6OmzRw-OYv"
      },
      "source": [
        "Question 1 : Write a function which takes a pandas dataframe, and column name and returns the mean, stdev, 25th Quantile, Median, 75th Quantile.\n",
        "\n",
        "**IMPORTANT NOTE**: The function you have written should pass the test. Only those which have passed will be considered for grades. An example is shown below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9rTd0fEt-uV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a966991-5c95-4b3f-b28a-a806ff53ca90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean  :  0.003834400000000011\n",
            "stdev :  1.1362988437142851\n",
            "Q1    :  -0.6395\n",
            "median:  0.039\n",
            "Q3    :  0.59675\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def prepare_data_det(data1):\n",
        "    data = data1.copy()\n",
        "    data['Direction'] = data['Direction'].replace('Up',1)\n",
        "    data['Direction'] = data['Direction'].replace('Down',0)\n",
        "    data['Direction'].astype('int')\n",
        "    return data\n",
        "\n",
        "def column_stats(data, col_name):\n",
        "  ### CODE HERE\n",
        "  ### Fill this function such that given a pandas datafarme data,\n",
        "  ### and column name col_name it will pass the test below.\n",
        "\n",
        "  data = prepare_data_det(data)\n",
        "  data_array = data[col_name]\n",
        "\n",
        "  mean = data_array.mean()\n",
        "  stdev = data_array.std()\n",
        "  Q1 = data_array.quantile(0.25)\n",
        "  median = data_array.median()\n",
        "  Q3 = data_array.quantile(0.75)\n",
        "\n",
        "  print(\"mean  : \",mean)\n",
        "  print(\"stdev : \",stdev)\n",
        "  print(\"Q1    : \",Q1)  \n",
        "  print(\"median: \",median)  \n",
        "  print(\"Q3    : \",Q3)  \n",
        "  return mean,stdev,Q1,median,Q3;\n",
        "  \n",
        "\n",
        "def test_column_stats():\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  data = pd.read_csv(\"/content/Smarket.csv\", index_col=0)\n",
        "  mean, stdev, Q1, median, Q3 = column_stats(data, 'Lag1')\n",
        "  assert np.abs(mean - 0.003834) < 1e-4\n",
        "  assert np.abs(stdev-1.136299) < 1e-4\n",
        "  assert np.abs(Q1 - -0.639500) < 1e-4\n",
        "  assert np.abs(median-0.039000) < 1e-4\n",
        "  assert np.abs(Q3-0.596750) < 1e-4\n",
        "test_column_stats()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKKpFbdmCA4W"
      },
      "source": [
        "Question 2: Split the dataset into train and test with sizes 998, 252 respectively.  Then fit a logistic regression model on this dataset.\n",
        "\n",
        "Report the following:\n",
        "\n",
        "1. Train Accuracy\n",
        "2. Test Accuracy\n",
        "3. `coef_` attribute\n",
        "4. `intercept_` attribute.\n",
        "\n",
        "Make sure the output is just the above quantities and nothing else.\n",
        "\n",
        "**IMPORTANT NOTE 1:** Do not shuffle the dataset while splitting. The first 998 rows should be taken as train and remaining 252 should be taken as test.\n",
        "\n",
        "**IMPORTANT NOTE 2:** Do not use the `Year` and `Today` for prediction.\n",
        "\n",
        "**IMPORTANT NOTE 3:** Consider `Up` to be class 1 and `Down` to be class 0.\n",
        "\n",
        "** Grading will be done on whether the test `test_classifier` function worked or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EDIBI0KDCpAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3877897-8336-4ca3-93d7-8c71831ee755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1. Train Accuracy      :  0.5250501002004008\n",
            " 2. Test Accuracy       :  0.48412698412698413\n",
            " 3. coef_ attribute     :  [[-0.05410202 -0.04559333  0.00727805  0.00653897 -0.00415829 -0.10995391]]\n",
            " 4. intercept_ attribute:  [0.18259423]\n",
            " \n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def prepare_data_set_Q2(data):\n",
        "    cols  = ['Lag1','Lag2','Lag3','Lag4','Lag5','Volume','Direction']\n",
        "    # select the wanted columns\n",
        "    data1 = data[cols]\n",
        "    df_data_set = data1.copy()\n",
        "    df_data_set['Direction'] = df_data_set['Direction'].replace('Up',1)\n",
        "    df_data_set['Direction'] = df_data_set['Direction'].replace('Down',0)\n",
        "    df_data_set['Direction'].astype('int')\n",
        "    return df_data_set\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "def get_LR_classifier():\n",
        "  data_set = pd.read_csv(\"/content/Smarket.csv\", index_col=0)\n",
        "  df_data_set = prepare_data_set_Q2(data_set)\n",
        "\n",
        "  Y = df_data_set.Direction\n",
        "  X = df_data_set.drop('Direction',axis=1)\n",
        "  \n",
        "\n",
        "  # split the data into train and test set with the required columns\n",
        "  XTrain = df_data_set.iloc[ 0 : 998, [0, 1, 2, 3, 4, 5] ]\n",
        "  yTrain = df_data_set.iloc[ 0 : 998, [6] ]\n",
        "\n",
        "  XTest = df_data_set.iloc[998 : , [0, 1, 2, 3, 4, 5] ]\n",
        "  yTest = df_data_set.iloc[998 : , [6] ]\n",
        "\n",
        "  clf = LogisticRegression()\n",
        "  clf.fit(XTrain, yTrain.values.ravel())\n",
        "  yPred = clf.predict(XTest)\n",
        "\n",
        "  print(' 1. Train Accuracy      : ',clf.score(XTrain, yTrain))\n",
        "  print(' 2. Test Accuracy       : ', clf.score(XTest, yTest))\n",
        "  print(' 3. coef_ attribute     : ', clf.coef_)\n",
        "  print(' 4. intercept_ attribute: ' , clf.intercept_)\n",
        "  print(' \\n\\n ')\n",
        "\n",
        "  return clf, XTrain, yTrain, XTest, yTest\n",
        "\n",
        "\n",
        "def test_LR_classifier():\n",
        "  clf, XTrain, yTrain, XTest, yTest = get_LR_classifier()\n",
        "  assert np.abs(clf.score(XTrain, yTrain) - 0.5250501002004008) < 1e-4\n",
        "  assert np.abs(clf.score(XTest, yTest) - 0.48412698412698413) < 1e-4\n",
        "  arr = np.array([[-0.05410202, -0.04559333,  0.00727805,  0.00653897, -0.00415829, -0.10995391]])\n",
        "  assert np.sum(np.abs(np.array(clf.coef_) - arr)) <6*1e-4\n",
        "  assert np.abs(clf.intercept_ - 0.18259423) < 1e-4\n",
        "\n",
        "test_LR_classifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MfnYe3uvgnYI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_oTKH1tDF2x"
      },
      "source": [
        "Question 3: Using the sklearn package `from sklearn.naive_bayes.GaussianNB` fit a naive bayes classifier. Use only the features `Lag2` and `Lag3` for this purpose.\n",
        "\n",
        "eport the following quantities from the properties of the classifier:\n",
        "\n",
        "1. `class_prior_`\n",
        "2. `theta_`\n",
        "3. `var_`\n",
        "4. Confusion Matrix for the test data.\n",
        "\n",
        "**IMPORTANT NOTE** The above quantities should be printed with correct labelling. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yd3Ffs8DE5r",
        "outputId": "cf475d93-b2fb-4c73-c8ec-83f4534ee2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. class_prior_:  [0.49198397 0.50801603]\n",
            "2. theta_      :  [[ 0.03389409 -0.00980652]\n",
            " [-0.03132544  0.00583432]]\n",
            "3. var_        :  [[1.53246749 1.52305652]\n",
            " [1.48732877 1.51198994]]\n",
            "4. Confusion Matrix for the test data:  [[  9 102]\n",
            " [  7 134]]\n",
            " \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prepare_data_set_Q3(data):\n",
        "    cols  = ['Lag2','Lag3','Direction']\n",
        "    # select the wanted columns\n",
        "    data1 = data[cols]\n",
        "    df_data_set = data1.copy()\n",
        "    df_data_set['Direction'] = df_data_set['Direction'].replace('Up',1)\n",
        "    df_data_set['Direction'] = df_data_set['Direction'].replace('Down',0)\n",
        "    df_data_set['Direction'].astype('int')\n",
        "\n",
        "    return df_data_set\n",
        "\n",
        "def get_NB_classifier():\n",
        "  data_set = pd.read_csv(\"/content/Smarket.csv\", index_col=0)\n",
        "  df_data_set = prepare_data_set_Q3(data_set)\n",
        "\n",
        "  Y = df_data_set.Direction\n",
        "  X = df_data_set.drop('Direction',axis=1)\n",
        "\n",
        "  # split the data into train and test set with the required columns\n",
        "  Xtrain = df_data_set.iloc[ 0 : 998, [0, 1] ]\n",
        "  yTrain = df_data_set.iloc[ 0 : 998, [2] ]\n",
        "\n",
        "  XTest = df_data_set.iloc[998 : , [0, 1] ]\n",
        "  yTest = df_data_set.iloc[998 : , [2] ]\n",
        "\n",
        "  clf = GaussianNB()\n",
        "  clf.fit(Xtrain, yTrain.values.ravel())\n",
        "  yPred = clf.predict(XTest)\n",
        "  Confusion_matrix = confusion_matrix(yTest, yPred)\n",
        "\n",
        "  print(\"1. class_prior_: \",clf.class_prior_)\n",
        "  print(\"2. theta_      : \",clf.theta_)\n",
        "  print(\"3. var_        : \",clf.var_)\n",
        "  print(\"4. Confusion Matrix for the test data: \",Confusion_matrix)\n",
        "  print(' \\n\\n')\n",
        "\n",
        "  return clf, Xtrain, yTrain, XTest, yTest\n",
        "\n",
        "def test_NB_classifier():\n",
        "  clf, Xtrain, yTrain, XTest, yTest = get_NB_classifier()\n",
        "  arr1 = np.array([0.49198397, 0.50801603])\n",
        "  assert np.sum(np.abs(np.array(clf.class_prior_) - arr1)) < 2*1e-4\n",
        "\n",
        "  arr2 = np.array([[ 0.03389409, -0.00980652],\n",
        "                    [-0.03132544,  0.00583432]])\n",
        "  assert np.sum(np.abs(np.array(clf.theta_) - arr2)) < 4*1e-4\n",
        "\n",
        "\n",
        "  arr3 = np.array([[1.23792871, 1.23412176],\n",
        "                   [1.21956089, 1.22963]])\n",
        "  assert np.sum(np.abs(np.array(np.sqrt(clf.var_)) - arr3)) <6*1e-4\n",
        "\n",
        "  arr4 = np.array([[  9, 102],\n",
        "                   [  7, 134]])\n",
        "  assert np.sum(np.abs(np.array(arr4) - arr4)) < 4*1e-4  \n",
        "  data.head()\n",
        "test_NB_classifier()  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "268e997add0bd0d65c7159c6175459e8c6395e34d7434aa9d10b5abb990f19c6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}