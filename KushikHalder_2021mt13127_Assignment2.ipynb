{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1:\n",
        "\n",
        "In this problem we will verify that ensembles indeed perform better than individual classifiers.\n",
        "\n",
        "Consider K set of binary classifiers. For simplicity we shall simulate the accuracy of each classifier using a\n",
        "probability value p. To do the ensemble, we repeat the following N times.\n",
        "\n",
        "\n",
        "\n",
        "*   Generate K random binary values in {0, 1} with probability of 1 being p. (Look at the function\n",
        "numpy.random.choice)\n",
        "*   Take a Majority Vote to predict the class.\n",
        "\n",
        "Now, accuracy is nothing but the percentage of times (out of N) we predict 1.\n",
        "\n",
        "\n",
        "**REASONING**: Essentially, we are assuming that an individual classifier is correct with probability p. So, if we generate K random binary values, we randomly guess if each of the K classifier is correct/wrong. So, if the majority vote is 1 then we have predicted the correct class, else we have predicted the wrong class. Hence accuracy is nothing but percentage of times (out of N) we predict value 1.\n",
        "\n",
        "Report the accuracy when we substitute the following values:\n",
        "\n",
        "> • p=0.49,K=1000,N=1000\n",
        "\n",
        "> • p=0.51,K=1000,N=1000 • p=0.51,K=10,N=1000\n",
        "\n",
        "> • p=0.51,K=1000,N=10\n",
        "\n",
        "> • p=0.51,K=100,N=10000"
      ],
      "metadata": {
        "id": "-42PXMaZKF8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Solution 1:**"
      ],
      "metadata": {
        "id": "8jrPfMvOKYJw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C1q66KhkqN1b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the Majority Vote of the classifier output\n",
        "def getMajorityVote(classifier_output_list):\n",
        "      correct_vote_count_1 = 0;\n",
        "      incorrect_vote_count_0 = 0;\n",
        "      classifier_output_Values = list(classifier_output_list)\n",
        "\n",
        "      correct_vote_count_1 = classifier_output_Values.count(1)\n",
        "      incorrect_vote_count_0 = classifier_output_Values.count(0)\n",
        "      #print(\" positive_vote_count_1 = \", positive_vote_count_1)\n",
        "      #print(\" negetive_vote_count_0 = \", negetive_vote_count_0)\n",
        "      if correct_vote_count_1 >= incorrect_vote_count_0:\n",
        "         return 1\n",
        "      else:\n",
        "         return 0\n",
        "\n",
        "#calculating the accuracy of each clasifier set K\n",
        "#now we are going iterate each set of defined classifier\n",
        "#initial Inputs definition\n",
        "sample_value_range = [ 1, 0 ]\n",
        "p_sample_gen_probab = [ 0.49, 0.51, 0.51, 0.51, 0.51 ]\n",
        "K_binary_classifiers_set = [ 1000, 1000, 10, 1000, 100 ]\n",
        "N_ensemble_itr_size = [ 1000, 1000, 1000, 10, 10000 ]\n",
        "\n",
        "correct_vote_count_1 = 0;\n",
        "correct_vote_count = 0;\n",
        "\n",
        "for index in range(len(K_binary_classifiers_set)):\n",
        "    #print(\"index = \",index)\n",
        "    ##classifier_output_Values = [0,1,0,1,1,0]\n",
        "    correct_vote_count_1 = 0\n",
        "    value = 0;\n",
        "    #print(\"N_ensemble_itr_size[index] = \",N_ensemble_itr_size[index])\n",
        "    for itera in range(N_ensemble_itr_size[index] ):\n",
        "        classifier_output_Values = np.random.choice( sample_value_range, \n",
        "                                                 K_binary_classifiers_set[index] +1, \n",
        "                                                 replace=True,\n",
        "                                                 p=[1-p_sample_gen_probab[index], p_sample_gen_probab[index]])\n",
        "    \n",
        "        majorityVote = getMajorityVote(classifier_output_Values)\n",
        "        #print(\"majorityVote MY = \",majorityVote);\n",
        "\n",
        "        if majorityVote == 1:\n",
        "            correct_vote_count_1 = correct_vote_count_1 + 1\n",
        "        \n",
        "    accuracy = correct_vote_count_1 / N_ensemble_itr_size[index]\n",
        "    accuracy = round((accuracy * 100),2)\n",
        "    #print(\"My accuracy = \",accuracy )\n",
        "\n",
        "    print(f\"Accuracy for p = {p_sample_gen_probab[index]}, K = {K_binary_classifiers_set[index]}, N = {N_ensemble_itr_size[index]} is {accuracy}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAYdRjfHwaoT",
        "outputId": "e0558c07-90e1-425c-d379-c931531c37f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for p = 0.49, K = 1000, N = 1000 is 72.5%\n",
            "Accuracy for p = 0.51, K = 1000, N = 1000 is 27.5%\n",
            "Accuracy for p = 0.51, K = 10, N = 1000 is 45.3%\n",
            "Accuracy for p = 0.51, K = 1000, N = 10 is 40.0%\n",
            "Accuracy for p = 0.51, K = 100, N = 10000 is 42.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_F3al6rh-TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2\n",
        "In this problem we shall look at the decision tree and fine tuning it. Do the following:\n",
        "\n",
        "> • Use the dataset from sklearn.datasets.make moons. Use the following parameter values random state = 42, n samples = 1000, noise = 0.4.\n",
        "\n",
        "> • Use train test split function with test size = 0.2 and random state = 42 to split the dataset into train and test.\n",
        "\n",
        "We only change two variables for this problem - max leaf nodes, min samples split. If nothing is specified take the default values. Report the following values\n",
        "\n",
        "> • Accuracy when max leaf nodes = 2\n",
        "\n",
        "> • Accuracy when max leaf nodes = 4\n",
        "\n",
        "> • Accuracy when min samples split = 30\n",
        "\n",
        "> • Using GridSearchCV identify the best hyperparameters within combinations max leaf nodes is in {2, 3, · · · , 99} and min samples split is in {2, 3, 4}. Report the best parameter combination and accuracy corresponding to it."
      ],
      "metadata": {
        "id": "1LNQ2aa6KTT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Solution 2:**"
      ],
      "metadata": {
        "id": "HaISnq9cKsjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "y8jbw_mSh-YS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g5hDhpoAJ5RU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_moons(n_samples=1000, noise=0.4, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=42)\n",
        "tree_clf = DecisionTreeClassifier()\n"
      ],
      "metadata": {
        "id": "s85eNUKwiYg7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy when `max_leaf_nodes = 2`"
      ],
      "metadata": {
        "id": "LJS1OLThnW-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param1 = {'max_leaf_nodes': [2] }\n",
        "clf = GridSearchCV(tree_clf, param1, scoring = \"accuracy\")\n",
        "clf.fit(X_train, y_train)\n",
        "pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Getting the training Accuracy score when max_leaf_node = 2 is : \", clf.score(X_train, y_train))\n",
        "print(\"Getting the f1 Accuracy on test data when max_leaf_node = 2 is : \", f1_score(y_test, pred))\n",
        "print(\"Getting the testing Accuracy score when max_leaf_node = 2 is : \", clf.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdH0OhOMnQtg",
        "outputId": "11759b7d-1b3d-4a0b-e08c-42353ca46cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting the training Accuracy score when max_leaf_node = 2 is :  0.78\n",
            "Getting the f1 Accuracy on test data when max_leaf_node = 2 is :  0.8095238095238095\n",
            "Getting the testing Accuracy score when max_leaf_node = 2 is :  0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy when `max_leaf_nodes = 4`"
      ],
      "metadata": {
        "id": "FPCOGcA3nZPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param2 = {'max_leaf_nodes': [4] }\n",
        "clf = GridSearchCV(tree_clf, param2, scoring = \"accuracy\")\n",
        "clf.fit(X_train, y_train)\n",
        "pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Getting the training Accuracy score when max_leaf_node = 4 is : \", clf.score(X_train, y_train))\n",
        "print(\"Getting the f1 Accuracy on test data when max_leaf_node = 4 is : \", f1_score(y_test, pred))\n",
        "print(\"Getting the testing Accuracy score when max_leaf_node = 4 is : \", clf.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2abLOfEncI-",
        "outputId": "c529aa57-3587-4570-8e1c-63a210edfd67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting the training Accuracy score when max_leaf_node = 4 is :  0.87\n",
            "Getting the f1 Accuracy on test data when max_leaf_node = 4 is :  0.8585365853658538\n",
            "Getting the testing Accuracy score when max_leaf_node = 4 is :  0.855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy when `min_samples_split = 30`"
      ],
      "metadata": {
        "id": "JfsNtlhYnkKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param3 = { 'min_samples_split': [30] }\n",
        "clf = GridSearchCV(tree_clf, param3, scoring = \"accuracy\")\n",
        "clf.fit(X_train, y_train)\n",
        "pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Getting the training Accuracy score when max_leaf_node = 30 is : \", clf.score(X_train, y_train))\n",
        "print(\"Getting the f1  Accuracy on test data when max_leaf_node = 30 is : \", f1_score(y_test, pred))\n",
        "print(\"Getting the testing Accuracy score when max_leaf_node = 30 is : \", clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvH3SOBjngQG",
        "outputId": "fc9e9030-a7eb-4d8f-93e6-3ef7a4a46b37"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting the training Accuracy score when max_leaf_node = 30 is :  0.90625\n",
            "Getting the f1  Accuracy on test data when max_leaf_node = 30 is :  0.8041237113402062\n",
            "Getting the testing Accuracy score when max_leaf_node = 30 is :  0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using GridSearchCV identify the best hyperparameters within combinations `max_leaf_nodes` is in {2, 3, · · · , 99} and `min_samples_split` is in {2, 3, 4}.\n",
        "\n",
        "### Report the best parameter combination and accuracy corresponding to it."
      ],
      "metadata": {
        "id": "pQcJe7BznpwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param4 = { 'max_leaf_nodes': list(range(2,99)), 'min_samples_split': [2, 3, 4] }\n",
        "clf = GridSearchCV(tree_clf, param4, scoring = \"accuracy\")\n",
        "clf.fit(X_train, y_train)\n",
        "pred = clf.predict(X_test)\n",
        "print (\"Best hyperparameters within combinations max leaf nodes is in {2, 3, · · · , 99} and min samples split is in {2, 3, 4} is:\", clf.best_params_)\n",
        "print(\"Corresponding training Accuracy score is:\", clf.score(X_train, y_train))\n",
        "print(\"Corresponding f1 Accuracy score on test data is : \", f1_score(y_test, pred))\n",
        "print(\"Corresponding test Accuracy score is : \", clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9_ndEU7ns1e",
        "outputId": "71b546ef-50cf-4af1-9ad2-fb88cbea3836"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters within combinations max leaf nodes is in {2, 3, · · · , 99} and min samples split is in {2, 3, 4} is: {'max_leaf_nodes': 6, 'min_samples_split': 2}\n",
            "Corresponding training Accuracy score is: 0.87\n",
            "Corresponding f1 Accuracy score on test data is :  0.8585365853658538\n",
            "Corresponding test Accuracy score is :  0.855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3\n",
        "Use LinearSVC to classify the following data points:\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "Report the following:\n",
        "• Value of .coef_\n",
        ",\n",
        "• Value of .intercept_"
      ],
      "metadata": {
        "id": "Eiq0ifHrn6ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "X = np.array([[3,4], [2,2], [4,4], [1,4], [2,1], [4,3], [4,1]])\n",
        "Y = [0,0,0,0,1,1,1]\n",
        "lsvc = LinearSVC()\n",
        "lsvc. fit(X, Y)\n",
        "print(\"Value of coef_ is:\" , lsvc.coef_)\n",
        "print(\"Value of intercept_ is:\", lsvc. intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qluvC_bYn7zm",
        "outputId": "866acb6c-f63f-40f2-e49e-2b8fd21963ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of coef_ is: [[ 0.88439959 -1.02510968]]\n",
            "Value of intercept_ is: [-0.08040337]\n"
          ]
        }
      ]
    }
  ]
}